{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from skimage.metrics import structural_similarity as ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hasan\\OneDrive\\Documents\\GitHub\\Vision-Transformer-Image-Dehazing-hasanhd555\\Vision\\data\\Outdoor\\color_correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hasan\\\\OneDrive\\\\Documents\\\\GitHub\\\\Vision-Transformer-Image-Dehazing-hasanhd555\\\\Vision\\\\data\\\\Outdoor\\\\color_correct'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Vision/data/Outdoor/color_correct/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hasan\\\\OneDrive\\\\Documents\\\\GitHub\\\\Vision-Transformer-Image-Dehazing-hasanhd555\\\\Vision\\\\data\\\\Outdoor\\\\color_correct'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a custom dataset class to load noisy and ground truth images\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "class ColorCorrectionDataset(Dataset):\n",
    "    def __init__(self, noisy_dir, gt_dir, transform=None):\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.gt_dir = gt_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get the list of filenames in both directories\n",
    "        self.noisy_images = os.listdir(noisy_dir)\n",
    "        self.gt_images = os.listdir(gt_dir)\n",
    "        \n",
    "        assert len(self.noisy_images) == len(self.gt_images), \"Number of noisy and GT images must be the same.\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        noisy_img_path = os.path.join(self.noisy_dir, self.noisy_images[index])\n",
    "        gt_img_path = os.path.join(self.gt_dir, self.gt_images[index])\n",
    "        \n",
    "        # Open images\n",
    "        noisy_img = Image.open(noisy_img_path).convert('RGB')\n",
    "        gt_img = Image.open(gt_img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms if specified\n",
    "        if self.transform:\n",
    "            noisy_img = self.transform(noisy_img)\n",
    "            gt_img = self.transform(gt_img)\n",
    "            \n",
    "        return noisy_img, gt_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the convolutional neural network architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ColorCorrectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorCorrectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.conv6 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(64)\n",
    "        self.conv9 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.conv9(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define SSIM loss function\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, win_size=11):\n",
    "        super(SSIMLoss, self).__init__()\n",
    "        self.win_size = win_size\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        output = output.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "        target = target.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "        ssim_loss = 1 - ssim(output, target, win_size=self.win_size, multichannel=True,channel_axis=3,data_range=1)\n",
    "        return torch.tensor(ssim_loss, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = ColorCorrectionDataset(noisy_dir='train/noisy', gt_dir='train/GT', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = ColorCorrectionDataset(noisy_dir='test/noisy', gt_dir='test/GT', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "#load one image\n",
    "noisy_img, gt_img = train_dataset[0]\n",
    "print(noisy_img.shape, gt_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/10], Loss: 0.9956\n",
      "Epoch [2/10], Step [10/10], Loss: 0.9951\n",
      "Epoch [3/10], Step [10/10], Loss: 0.9957\n",
      "Epoch [4/10], Step [10/10], Loss: 0.9956\n",
      "Epoch [5/10], Step [10/10], Loss: 0.9951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "model = ColorCorrectionCNN().to(device)\n",
    "criterion = SSIMLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_values = []\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (noisy_img, gt_img) in enumerate(train_loader):\n",
    "        noisy_img, gt_img = noisy_img.to(device), gt_img.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_img)\n",
    "        loss = criterion(outputs, gt_img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/10:.4f}\")\n",
    "            running_loss = 0.0\n",
    "    loss_values.append(running_loss)\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "total_ssim_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (noisy_img, gt_img) in enumerate(test_loader):\n",
    "        noisy_img, gt_img = noisy_img.to(device), gt_img.to(device)\n",
    "        outputs = model(noisy_img)\n",
    "        loss = criterion(outputs, gt_img)\n",
    "        total_ssim_loss += loss.item()\n",
    "\n",
    "print(f\"Average SSIM loss on test set: {total_ssim_loss/len(test_loader):.4f}\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Visualize the loss over epochs\n",
    "plt.plot(np.arange(1, num_epochs+1), loss_values)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'color_correction_model.pth')\n",
    "print(\"Model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
